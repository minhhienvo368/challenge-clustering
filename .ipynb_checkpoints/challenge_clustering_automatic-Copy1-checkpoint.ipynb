{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a887fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data analysis libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import itertools\n",
    "\n",
    "#Visualization and statistics libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.pyplot import style\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "style.use('seaborn')\n",
    "\n",
    "# Model related libraries\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ea6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearing = pd.read_csv(\"df_96features.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48be59cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hert_std', 'hert_median', 'hert_max', 'hert_min', 'hert_entropy',\n",
       "       'hert_impulse', 'hert_margin', 'hert_frequence', 'hert_MS_F',\n",
       "       'hert_RMQ_F', 'hert_RV_F', 'hert_crest_F', 'w_std', 'w_median', 'w_max',\n",
       "       'w_min', 'w_entropy', 'w_impulse', 'w_margin', 'w_frequence', 'w_MS_F',\n",
       "       'w_RMQ_F', 'w_RV_F', 'w_crest_F', 'a1_x_std', 'a1_x_median', 'a1_x_max',\n",
       "       'a1_x_min', 'a1_x_entropy', 'a1_x_impulse', 'a1_x_margin',\n",
       "       'a1_x_frequence', 'a1_x_MS_F', 'a1_x_RMQ_F', 'a1_x_RV_F',\n",
       "       'a1_x_crest_F', 'a2_x_std', 'a2_x_median', 'a2_x_max', 'a2_x_min',\n",
       "       'a2_x_entropy', 'a2_x_impulse', 'a2_x_margin', 'a2_x_frequence',\n",
       "       'a2_x_MS_F', 'a2_x_RMQ_F', 'a2_x_RV_F', 'a2_x_crest_F', 'a1_y_std',\n",
       "       'a1_y_median', 'a1_y_max', 'a1_y_min', 'a1_y_entropy', 'a1_y_impulse',\n",
       "       'a1_y_margin', 'a1_y_frequence', 'a1_y_MS_F', 'a1_y_RMQ_F', 'a1_y_RV_F',\n",
       "       'a1_y_crest_F', 'a2_y_std', 'a2_y_median', 'a2_y_max', 'a2_y_min',\n",
       "       'a2_y_entropy', 'a2_y_impulse', 'a2_y_margin', 'a2_y_frequence',\n",
       "       'a2_y_MS_F', 'a2_y_RMQ_F', 'a2_y_RV_F', 'a2_y_crest_F', 'a1_z_std',\n",
       "       'a1_z_median', 'a1_z_max', 'a1_z_min', 'a1_z_entropy', 'a1_z_impulse',\n",
       "       'a1_z_margin', 'a1_z_frequence', 'a1_z_MS_F', 'a1_z_RMQ_F', 'a1_z_RV_F',\n",
       "       'a1_z_crest_F', 'a2_z_std', 'a2_z_median', 'a2_z_max', 'a2_z_min',\n",
       "       'a2_z_entropy', 'a2_z_impulse', 'a2_z_margin', 'a2_z_frequence',\n",
       "       'a2_z_MS_F', 'a2_z_RMQ_F', 'a2_z_RV_F', 'a2_z_crest_F'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bearing.drop([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be346c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ef0a93f0255a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbearing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbearing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "combinations = list(itertools.combinations(bearing.columns,2))\n",
    "print(combinations)\n",
    "\n",
    "\n",
    "# add cluster index to dataframe\n",
    "\n",
    "bearing = bearing[['a1_x_entropy','a1_y_entropy','a1_z_entropy', 'hert_median', 'hert_max', 'hert_min',\n",
    "                  'a1_x_median', 'a1_x_max','a1_x_min', 'a1_x_entropy']]\n",
    "scaler = StandardScaler()\n",
    "bearing = pd.DataFrame(scaler.fit_transform(bearing), index=bearing.index, columns=bearing.columns)\n",
    "\n",
    "\n",
    "for feature1,feature2 in combinations:    \n",
    "    X = bearing[[feature1, feature2]].values\n",
    "    range_n_clusters = [2, 3, 4, 5, 6]\n",
    "    silhouette_avg_n_clusters = []\n",
    "\n",
    "    print(f'With 2-features combination of: {feature1}, {feature2}')\n",
    "\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Create a subplot with 1 row and 2 columns\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(18, 7)\n",
    "\n",
    "        # The 1st subplot is the silhouette plot\n",
    "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "        # lie within [-0.1, 1]\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "        # plots of individual clusters, to demarcate them clearly.\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        silhouette_avg_n_clusters.append(silhouette_avg)\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "        ax2.scatter(X[:, 0], X[:, 1], marker='.', s=300, lw=0, alpha=0.7,\n",
    "                    c=colors, edgecolor='k')\n",
    "\n",
    "        # Labeling the clusters\n",
    "        centers = clusterer.cluster_centers_\n",
    "        # Draw white circles at cluster centers\n",
    "        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                    c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                        s=50, edgecolor='k')\n",
    "\n",
    "        ax2.set_title(\"The visualization of the clustered data.\")\n",
    "        ax2.set_xlabel(feature1)\n",
    "        ax2.set_ylabel(feature2)\n",
    "\n",
    "        plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                      \"with n_clusters = %d\" % n_clusters),\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    style.use(\"fivethirtyeight\")\n",
    "    plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
    "    plt.xlabel(\"Number of Clusters (k)\")\n",
    "    plt.ylabel(\"silhouette score\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0dd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
